{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.strings import StringStore,hash_string\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Token,Span\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Framing(object):\n",
    "    name='Framing'\n",
    "    \n",
    "    def __init__(self,nlp):\n",
    "        \n",
    "\n",
    "        self.matcher = Matcher(nlp.vocab)\n",
    "        age_1 = [{'DEP': 'nsubj'},\n",
    "               {'LEMMA': 'be'},\n",
    "               {'LIKE_NUM': True},\n",
    "               {'LEMMA': 'year','OP':'?'},\n",
    "               {'ORTH': 'old','OP':'?'}]\n",
    "        \n",
    "        smoke1 = [{'DEP': 'nsubj','OP':'?'},\n",
    "                  {'LEMMA':'DO','OP':'?'},\n",
    "             {'LEMMA':'not','OP':'!'},\n",
    "             {'LEMMA':'smoke'}]\n",
    "        smoke2 = [{'DEP': 'nsubj','OP':'?'},\n",
    "           {'LEMMA': 'be'},\n",
    "            {'LEMMA':'not','OP':'!'},\n",
    "           {'POS': 'DET','OP':'?'},\n",
    "           {'LEMMA': 'smoker'}]\n",
    "        \n",
    "        subject1 = [{'DEP': 'nsubj'},\n",
    "           {'LEMMA': 'be'},\n",
    "           {'ENT_TYPE': 'PERSON'}]\n",
    "        subject2 = [{'POS': 'PRON'},\n",
    "           {'LOWER': 'name'},\n",
    "           {'LEMMA': 'be'},\n",
    "           {'ENT_TYPE': 'PERSON'}]\n",
    "        \n",
    "        subject_p1 = [{'DEP':'nsubj'},{'POS': 'PRON'}]\n",
    "        subject_p2 = [{'LOWER': 'my'},\n",
    "               {'POS': 'NOUN'},\n",
    "                     {'LEMMA': 'be'}]\n",
    "        \n",
    "        live_in1 = [{'DEP':'nsubj','OP':'?'},\n",
    "                  {'LEMMA':'be'},\n",
    "                  {'LOWER': 'from'},\n",
    "                  {'ENT_TYPE':'GPE'}]\n",
    "        live_in2 = [{'DEP':'nsubj','OP':'?'},\n",
    "          {'LEMMA':'live'},\n",
    "          {'LOWER': 'in'},\n",
    "          {'ENT_TYPE':'GPE'}]\n",
    "\n",
    "        \n",
    "        self.matcher.add('smoking pattern',[smoke1,smoke2])\n",
    "        self.matcher.add('Age',[age_1])\n",
    "        self.matcher.add('Personal',[subject1,subject2])\n",
    "        self.matcher.add('Pronoun',[subject_p1,subject_p2])\n",
    "        self.matcher.add('Location',[live_in1,live_in2])\n",
    "        \n",
    "        Token.set_extension(\"is_age\",default=False)\n",
    "        Token.set_extension(\"is_smoker\",default=False)\n",
    "        Token.set_extension(\"is_name\",default=False)\n",
    "        Token.set_extension(\"is_pronoun\",default=False)\n",
    "        Token.set_extension(\"is_relative\",default=False)\n",
    "        Token.set_extension(\"is_living\",default=False)\n",
    "        \n",
    "        \n",
    "    def __call__(self,doc):\n",
    "        matches = self.matcher(doc)\n",
    "        \n",
    "        for match_id,start,end in matches:\n",
    "            if match_id == hash_string(\"Age\"):\n",
    "                span = doc[start:end]  # The matched span\n",
    "                age = ([token for token in span.subtree if token.like_num][0])\n",
    "                age._.set(\"is_age\",True)\n",
    "                string_id = nlp.vocab.strings[match_id] \n",
    "                print('pattern:',string_id)\n",
    "                print('Age:', age)\n",
    "                print(span)\n",
    "                \n",
    "                \n",
    "            if match_id == hash_string(\"smoking pattern\"):\n",
    "                entity = Span(doc, start, end, label=\"smoker\")\n",
    "                span = doc[start:end]  # The matched span\n",
    "                string_id = nlp.vocab.strings[match_id] \n",
    "                print('pattern:',string_id)\n",
    "                print(span)\n",
    "                for token in entity:  # set values of token attributes\n",
    "                    token._.set(\"is_smoker\", True)\n",
    "                    \n",
    "            if match_id == hash_string(\"Personal\"):\n",
    "                entity = Span(doc, start, end)\n",
    "                span = doc[start:end]  # The matched span\n",
    "                string_id = nlp.vocab.strings[match_id] \n",
    "                print('pattern:',string_id)\n",
    "                print(span)\n",
    "                for token in entity:# set values of token attributes\n",
    "                    print(token)\n",
    "                    if token.ent_type_ == 'PERSON':\n",
    "                        token._.set(\"is_name\", True)\n",
    "                        \n",
    "            if match_id == hash_string(\"Pronoun\"):\n",
    "                entity = Span(doc, start, end)\n",
    "                span = doc[start:end]  # The matched span\n",
    "                string_id = nlp.vocab.strings[match_id] \n",
    "                print('pattern:',string_id)\n",
    "                print(span)\n",
    "                for token in entity:# set values of token attributes\n",
    "                    if token.dep_ == 'nsubj':\n",
    "                        token._.set(\"is_pronoun\", True)\n",
    "                        \n",
    "            if match_id == hash_string(\"Location\"):\n",
    "                entity = Span(doc, start, end)\n",
    "                span = doc[start:end]  # The matched span\n",
    "                string_id = nlp.vocab.strings[match_id] \n",
    "                print('pattern:',string_id)\n",
    "                print(span)\n",
    "                for token in entity:# set values of token attributes\n",
    "                    if token.ent_type_ == 'GPE':\n",
    "                        token._.set(\"is_living\", True)\n",
    "                \n",
    "        return doc\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "component=Framing(nlp)\n",
    "nlp.add_pipe(component,last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define  frame dictionary\n",
    "\n",
    "Frame={'age': 0, 'live_in': 0, 'pronoun': 0,'name':0,'smoker':False }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern: Pronoun\n",
      "My mother is\n",
      "pattern: Age\n",
      "Age: 35\n",
      "mother is 35\n",
      "pattern: Location\n",
      "lives in Italy\n",
      "pattern: Personal\n",
      "name is Laura\n",
      "name\n",
      "is\n",
      "Laura\n",
      "HERE I WOULD FILL THE SLOTS\n",
      "not a smoker!!!!\n",
      "location Italy\n",
      "name Laura\n",
      "pronoun mother\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc=nlp(u\"My mother is 35. She doesn't smokes and lives in Italy. Her name is Laura.\")\n",
    "\n",
    "\n",
    "print('HERE I WOULD FILL THE SLOTS')\n",
    "\n",
    "#Age\n",
    "age_slot = ([(token.text) for token in doc if token._.is_age])\n",
    "if not age_slot:\n",
    "    print('The age is missing')\n",
    "else:\n",
    "    Frame['age'] = age_slot[0]\n",
    "\n",
    "    \n",
    "#smoker\n",
    "if not ([(token.text) for token in doc if token._.is_smoker]):\n",
    "    print('not a smoker!!!!')\n",
    "    Frame['smoker'] = False\n",
    "else:\n",
    "    print('smoker')\n",
    "    Frame['smoker'] = True\n",
    "    \n",
    "\n",
    "\n",
    "#Location\n",
    "loc = ([(token.text) for token in doc if token._.is_living])\n",
    "if not loc:\n",
    "    print('Location missing')\n",
    "else:\n",
    "    print('location', loc[0] )\n",
    "    Frame['live_in']  = loc[0]\n",
    "    \n",
    "#Name\n",
    "\n",
    "name = ([(token.text) for token in doc if token._.is_name])\n",
    "if not name:\n",
    "    print('Personal name missing')\n",
    "else:\n",
    "    print('name', name[0] )\n",
    "    Frame['name']  = name[0]\n",
    "\n",
    "#Pronoun\n",
    "pronoun = ([(token.text) for token in doc if token._.is_pronoun])\n",
    "if not pronoun:\n",
    "    print('Pronoun missing')\n",
    "else:\n",
    "    for item in pronoun:\n",
    "        print('pronoun', item )\n",
    "        Frame['pronoun']  = item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': '35', 'live_in': 'Italy', 'pronoun': 'mother', 'name': 'Laura', 'smoker': False}\n"
     ]
    }
   ],
   "source": [
    "print(Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_hrisk= ['chemotherapy','immunotherapy','radiotherapy','leukaemia',\n",
    "                   'lymphoma','myeloma','transplant','immunosuppressant','cancer','pregnant']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u\"I am Laura and I am 28 years old and a smoker\")\n",
    "print([(token.text) for token in doc if token._.is_age])\n",
    "print([(token.text) for token in doc if token._.is_smoker])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
